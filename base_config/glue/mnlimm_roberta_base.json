{
    "data_reader": {
        "dataset": "mnli_bert",
        "train_file_path": "MNLI/train.tsv",
        "valid_file_path": "MNLI/dev_mismatched.tsv",
        "mnli_bert": {
            "sequence_max_length": 128,
            "cls_token": "<s>",
            "sep_token": "</s>",
            "input_type": "roberta"
        }
    },
    "iterator": {
        "batch_size": 32
    },
    "token": {
        "names": ["feature"],
        "types": ["feature"],
        "tokenizer": {
            "bpe": {
               "name": "roberta",
               "roberta": {
                   "vocab_path": "https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json",
                   "merges_path": "https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt"
               }
            }
        },
        "feature": {
            "vocab": {
                "pretrained_path": "https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json",
                "pretrained_token": "all",
                "pad_token": "<pad>",
                "oov_token": "<unk>"
            },
            "indexer": {
                "do_tokenize": false
            }
        }
    },
    "model": {
        "name": "roberta_for_seq_cls",
        "roberta_for_seq_cls": {
            "pretrained_model_name": "roberta-base",
            "dropout": 0.1
        }
    },
    "trainer": {
        "log_dir": "logs/glue/mnlimm_roberta_base",
        "num_epochs": 5,
        "early_stopping_threshold": 10,
        "metric_key": "accuracy",
        "eval_and_save_step_count": 1000
    },
    "optimizer": {
        "learning_rate": 2e-5,
        "op_type": "adamw",
        "adamw": {
            "weight_decay": 0
        }
    },
    "seed_num": 42
}
