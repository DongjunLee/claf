 {
     "data_reader": {
         "dataset": "conll2003_bert",
         "train_file_path": "https://github.com/Franck-Dernoncourt/NeuroNER/blob/master/neuroner/data/conll2003/en/train.txt?raw=true",
         "valid_file_path": "https://github.com/Franck-Dernoncourt/NeuroNER/blob/master/neuroner/data/conll2003/en/valid.txt?raw=true",
         "conll2003_bert": {
             "sequence_max_length": 128,
             "ignore_tag_idx": -1
         }
     },
     "iterator": {
         "batch_size": 64
     },
     "token": {
         "names": ["feature"],
         "types": ["feature"],
         "tokenizer": {
             "subword": {
                 "name": "wordpiece",
                 "wordpiece": {
                     "vocab_path": "https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt"
                 }
             },
             "word": {
                 "name": "bert_basic",
                 "bert_basic": {
                     "do_lower_case": false
                 }
             }
         },
         "feature": {
             "vocab": {
                 "pretrained_path": "https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt",
                 "pretrained_token": "all"
             },
             "indexer": {
                 "do_tokenize": false
             }
         }
     },
     "model": {
         "name": "bert_for_tok_cls",
         "bert_for_tok_cls": {
             "pretrained_model_name": "bert-base-uncased",
             "criterion": {
                  "name": "cross_entropy"
             }
         }
     },
     "trainer": {
         "log_dir": "logs/cola_bert_base",
         "num_epochs": 10,
         "early_stopping_threshold": 10,
         "metric_key": "class_accuracy",
         "eval_and_save_step_count": "epoch"
     },
     "optimizer": {
         "op_type": "bert_adam",
         "learning_rate": 1e-5
     },
     "seed_num": 42
 }
