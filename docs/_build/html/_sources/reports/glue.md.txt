# GLUE

- [`GLUE`](https://gluebenchmark.com/): The General Language Understanding Evaluation (GLUE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems. 

---

## Results

- Dev Set

| Model | CoLA (Matt) | MNLIm (Acc) | MNLImm (Acc) | MRPC (Acc/F1) | QNLI (Acc) | QQP (Acc/F1) | RTE (Acc) | SST-2 (Acc) | STS-B (Pea/Spe) | WNLI (Acc) | 
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **BERT** Base, Uncased | 59.393 | 83.923 | 84.306 | 87.5/91.282 | 88.521 | 90.378/87.171 |  69.314 |  92.546 |  88.070/87.881 | 56.338 | 