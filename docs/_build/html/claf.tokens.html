

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>claf.tokens package &mdash; CLaF 0.2.0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="claf.tokens.embedding package" href="claf.tokens.embedding.html" />
    <link rel="prev" title="claf.modules.layer package" href="claf.modules.layer.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html">
          

          
            
            <img src="_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.2.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="contents/dataset_and_model.html">Dataset and Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="contents/pretrained_vector.html">Pretrained Vector</a></li>
<li class="toctree-l1"><a class="reference internal" href="contents/tokens.html">Tokens</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="claf.config.html">config</a></li>
<li class="toctree-l1"><a class="reference internal" href="claf.data.html">data</a></li>
<li class="toctree-l1"><a class="reference internal" href="claf.learn.html">learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="claf.metric.html">metric</a></li>
<li class="toctree-l1"><a class="reference internal" href="claf.model.html">model</a></li>
<li class="toctree-l1"><a class="reference internal" href="claf.modules.html">modules</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">tokens</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="claf.tokens.embedding.html">claf.tokens.embedding package</a></li>
<li class="toctree-l3"><a class="reference internal" href="claf.tokens.indexer.html">claf.tokens.indexer package</a></li>
<li class="toctree-l3"><a class="reference internal" href="claf.tokens.token_embedder.html">claf.tokens.token_embedder package</a></li>
<li class="toctree-l3"><a class="reference internal" href="claf.tokens.tokenizer.html">claf.tokens.tokenizer package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-claf.tokens.cove">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-claf.tokens">Module contents</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Reports</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reports/glue.html">GLUE</a></li>
<li class="toctree-l1"><a class="reference internal" href="reports/historyqa.html">HistoryQA</a></li>
<li class="toctree-l1"><a class="reference internal" href="reports/korquad.html">KorQuAD</a></li>
<li class="toctree-l1"><a class="reference internal" href="reports/squad.html">SQuAD</a></li>
<li class="toctree-l1"><a class="reference internal" href="reports/wikisql.html">WikiSQL</a></li>
</ul>
<p class="caption"><span class="caption-text">Summary</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="summary/reading_comprehension.html">Reading Comprehension</a></li>
</ul>
<p class="caption"><span class="caption-text">Appendix</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">CLaF</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>claf.tokens package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/claf.tokens.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="claf-tokens-package">
<h1>claf.tokens package<a class="headerlink" href="#claf-tokens-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="claf.tokens.embedding.html">claf.tokens.embedding package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="claf.tokens.embedding.html#module-claf.tokens.embedding.base">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="claf.tokens.embedding.html#module-claf.tokens.embedding">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="claf.tokens.indexer.html">claf.tokens.indexer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="claf.tokens.indexer.html#module-claf.tokens.indexer.base">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="claf.tokens.indexer.html#module-claf.tokens.indexer">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="claf.tokens.token_embedder.html">claf.tokens.token_embedder package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="claf.tokens.token_embedder.html#module-claf.tokens.token_embedder.base">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="claf.tokens.token_embedder.html#module-claf.tokens.token_embedder">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="claf.tokens.tokenizer.html">claf.tokens.tokenizer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="claf.tokens.tokenizer.html#module-claf.tokens.tokenizer.base">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="claf.tokens.tokenizer.html#module-claf.tokens.tokenizer">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="module-claf.tokens.cove">
<span id="submodules"></span><h2>Submodules<a class="headerlink" href="#module-claf.tokens.cove" title="Permalink to this headline">¶</a></h2>
<p>This code is from salesforce/cove
(<a class="reference external" href="https://github.com/salesforce/cove/blob/master/cove/encoder.py">https://github.com/salesforce/cove/blob/master/cove/encoder.py</a>)</p>
<dl class="class">
<dt id="claf.tokens.cove.MTLSTM">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.cove.</code><code class="sig-name descname">MTLSTM</code><span class="sig-paren">(</span><em class="sig-param">word_embedding</em>, <em class="sig-param">pretrained_path=None</em>, <em class="sig-param">requires_grad=False</em>, <em class="sig-param">residual_embeddings=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/cove.html#MTLSTM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.cove.MTLSTM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="claf.tokens.cove.MTLSTM.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/cove.html#MTLSTM.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.cove.MTLSTM.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>A pretrained MT-LSTM (McCann et. al. 2017).
This LSTM was trained with 300d 840B GloVe on the WMT 2017 machine translation dataset.</p>
<dl>
<dt>Arguments:</dt><dd><dl class="simple">
<dt>inputs (Tensor): If MTLSTM handles embedding, a Long Tensor of size (batch_size, timesteps).</dt><dd><p>Otherwise, a Float Tensor of size (batch_size, timesteps, features).</p>
</dd>
</dl>
<p>lengths (Long Tensor): (batch_size, lengths) lenghts of each sequence for handling padding
hidden (Float Tensor): initial hidden state of the LSTM</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="module-claf.tokens.elmo"></span><p>This code is from allenai/allennlp
(<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/modules/elmo.py">https://github.com/allenai/allennlp/blob/master/allennlp/modules/elmo.py</a>)</p>
<dl class="class">
<dt id="claf.tokens.elmo.Elmo">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.elmo.</code><code class="sig-name descname">Elmo</code><span class="sig-paren">(</span><em class="sig-param">options_file: str</em>, <em class="sig-param">weight_file: str</em>, <em class="sig-param">num_output_representations: int</em>, <em class="sig-param">requires_grad: bool = False</em>, <em class="sig-param">do_layer_norm: bool = False</em>, <em class="sig-param">dropout: float = 0.5</em>, <em class="sig-param">vocab_to_cache: List[str] = None</em>, <em class="sig-param">module: torch.nn.modules.module.Module = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/elmo.html#Elmo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.elmo.Elmo" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Compute ELMo representations using a pre-trained bidirectional language model.
See “Deep contextualized word representations”, Peters et al. for details.
This module takes character id input and computes <code class="docutils literal notranslate"><span class="pre">num_output_representations</span></code> different layers
of ELMo representations.  Typically <code class="docutils literal notranslate"><span class="pre">num_output_representations</span></code> is 1 or 2.  For example, in
the case of the SRL model in the above paper, <code class="docutils literal notranslate"><span class="pre">num_output_representations=1</span></code> where ELMo was included at
the input token representation layer.  In the case of the SQuAD model, <code class="docutils literal notranslate"><span class="pre">num_output_representations=2</span></code>
as ELMo was also included at the GRU output layer.
In the implementation below, we learn separate scalar weights for each output layer,
but only run the biLM once on each input sequence for efficiency.
Parameters
———-
options_file : <code class="docutils literal notranslate"><span class="pre">str</span></code>, required.</p>
<blockquote>
<div><p>ELMo JSON options file</p>
</div></blockquote>
<dl>
<dt>weight_file<span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, required.</span></dt><dd><p>ELMo hdf5 weight file</p>
</dd>
<dt>num_output_representations: <code class="docutils literal notranslate"><span class="pre">int</span></code>, required.</dt><dd><p>The number of ELMo representation layers to output.</p>
</dd>
<dt>requires_grad: <code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional</dt><dd><p>If True, compute gradient of ELMo parameters for fine tuning.</p>
</dd>
<dt>do_layer_norm<span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional, (default=False).</span></dt><dd><p>Should we apply layer normalization (passed to <code class="docutils literal notranslate"><span class="pre">ScalarMix</span></code>)?</p>
</dd>
<dt>dropout<span class="classifier"><code class="docutils literal notranslate"><span class="pre">float</span></code>, optional, (default = 0.5).</span></dt><dd><p>The dropout to be applied to the ELMo representations.</p>
</dd>
<dt>vocab_to_cache<span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[str]</span></code>, optional, (default = 0.5).</span></dt><dd><p>A list of words to pre-compute and cache character convolutions
for. If you use this option, Elmo expects that you pass word
indices of shape (batch_size, timesteps) to forward, instead
of character indices. If you use this option and pass a word which
wasn’t pre-cached, this will break.</p>
</dd>
<dt>module<span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, optional, (default = None).</span></dt><dd><p>If provided, then use this module instead of the pre-trained ELMo biLM.
If using this option, then pass <code class="docutils literal notranslate"><span class="pre">None</span></code> for both <code class="docutils literal notranslate"><span class="pre">options_file</span></code>
and <code class="docutils literal notranslate"><span class="pre">weight_file</span></code>.  The module must provide a public attribute
<code class="docutils literal notranslate"><span class="pre">num_layers</span></code> with the number of internal layers and its <code class="docutils literal notranslate"><span class="pre">forward</span></code>
method must return a <code class="docutils literal notranslate"><span class="pre">dict</span></code> with <code class="docutils literal notranslate"><span class="pre">activations</span></code> and <code class="docutils literal notranslate"><span class="pre">mask</span></code> keys
(see <cite>_ElmoBilm`</cite> for an example).  Note that <code class="docutils literal notranslate"><span class="pre">requires_grad</span></code> is also
ignored with this option.</p>
</dd>
</dl>
<dl class="method">
<dt id="claf.tokens.elmo.Elmo.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs: torch.Tensor</em>, <em class="sig-param">word_inputs: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Dict[str, Union[torch.Tensor, List[torch.Tensor]]]<a class="reference internal" href="_modules/claf/tokens/elmo.html#Elmo.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.elmo.Elmo.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>inputs: <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>, required.
Shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps,</span> <span class="pre">50)</span></code> of character ids representing the current batch.
word_inputs : <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>, required.</p>
<blockquote>
<div><p>If you passed a cached vocab, you can in addition pass a tensor of shape
<code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps)</span></code>, which represent word ids which have been pre-cached.</p>
</div></blockquote>
<p>Dict with keys:
<code class="docutils literal notranslate"><span class="pre">'elmo_representations'</span></code>: <code class="docutils literal notranslate"><span class="pre">List[torch.Tensor]</span></code></p>
<blockquote>
<div><p>A <code class="docutils literal notranslate"><span class="pre">num_output_representations</span></code> list of ELMo representations for the input sequence.
Each representation is shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps,</span> <span class="pre">embedding_dim)</span></code></p>
</div></blockquote>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">'mask'</span></code>:  <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></dt><dd><p>Shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps)</span></code> long tensor with sequence mask.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="claf.tokens.elmo.Elmo.from_params">
<em class="property">classmethod </em><code class="sig-name descname">from_params</code><span class="sig-paren">(</span><em class="sig-param">params</em><span class="sig-paren">)</span> &#x2192; claf.tokens.elmo.Elmo<a class="reference internal" href="_modules/claf/tokens/elmo.html#Elmo.from_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.elmo.Elmo.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.elmo.Elmo.get_output_dim">
<code class="sig-name descname">get_output_dim</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/elmo.html#Elmo.get_output_dim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.elmo.Elmo.get_output_dim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="claf.tokens.elmo.ElmoLstm">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.elmo.</code><code class="sig-name descname">ElmoLstm</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">hidden_size: int</em>, <em class="sig-param">cell_size: int</em>, <em class="sig-param">num_layers: int</em>, <em class="sig-param">requires_grad: bool = False</em>, <em class="sig-param">recurrent_dropout_probability: float = 0.0</em>, <em class="sig-param">memory_cell_clip_value: Optional[float] = None</em>, <em class="sig-param">state_projection_clip_value: Optional[float] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/elmo.html#ElmoLstm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.elmo.ElmoLstm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">claf.modules.encoder.lstm_cell_with_projection._EncoderBase</span></code></p>
<p>A stacked, bidirectional LSTM which uses
<code class="xref py py-class docutils literal notranslate"><span class="pre">LstmCellWithProjection</span></code>’s
with highway layers between the inputs to layers.
The inputs to the forward and backward directions are independent - forward and backward
states are not concatenated between layers.
Additionally, this LSTM maintains its <cite>own</cite> state, which is updated every time
<code class="docutils literal notranslate"><span class="pre">forward</span></code> is called. It is dynamically resized for different batch sizes and is
designed for use with non-continuous inputs (i.e inputs which aren’t formatted as a stream,
such as text used for a language modelling task, which is how stateful RNNs are typically used).
This is non-standard, but can be thought of as having an “end of sentence” state, which is
carried across different sentences.
Parameters
———-
input_size : <code class="docutils literal notranslate"><span class="pre">int</span></code>, required</p>
<blockquote>
<div><p>The dimension of the inputs to the LSTM.</p>
</div></blockquote>
<dl>
<dt>hidden_size<span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, required</span></dt><dd><p>The dimension of the outputs of the LSTM.</p>
</dd>
<dt>cell_size<span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, required.</span></dt><dd><p>The dimension of the memory cell of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">LstmCellWithProjection</span></code>.</p>
</dd>
<dt>num_layers<span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, required</span></dt><dd><p>The number of bidirectional LSTMs to use.</p>
</dd>
<dt>requires_grad: <code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional</dt><dd><p>If True, compute gradient of ELMo parameters for fine tuning.</p>
</dd>
<dt>recurrent_dropout_probability: <code class="docutils literal notranslate"><span class="pre">float</span></code>, optional (default = 0.0)</dt><dd><p>The dropout probability to be used in a dropout scheme as stated in
<a class="reference external" href="https://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a> .</p>
</dd>
<dt>state_projection_clip_value: <code class="docutils literal notranslate"><span class="pre">float</span></code>, optional, (default = None)</dt><dd><p>The magnitude with which to clip the hidden_state after projecting it.</p>
</dd>
<dt>memory_cell_clip_value: <code class="docutils literal notranslate"><span class="pre">float</span></code>, optional, (default = None)</dt><dd><p>The magnitude with which to clip the memory cell.</p>
</dd>
</dl>
<dl class="method">
<dt id="claf.tokens.elmo.ElmoLstm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs: torch.Tensor</em>, <em class="sig-param">mask: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/claf/tokens/elmo.html#ElmoLstm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.elmo.ElmoLstm.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>inputs<span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>, required.</span></dt><dd><p>A Tensor of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length,</span> <span class="pre">hidden_size)</span></code>.</p>
</dd>
<dt>mask<span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.LongTensor</span></code>, required.</span></dt><dd><p>A binary mask of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code> representing the
non-padded elements in each sequence in the batch.</p>
</dd>
</dl>
<p>A <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> of shape (num_layers, batch_size, sequence_length, hidden_size),
where the num_layers dimension represents the LSTM output from that layer.</p>
</dd></dl>

<dl class="method">
<dt id="claf.tokens.elmo.ElmoLstm.load_weights">
<code class="sig-name descname">load_weights</code><span class="sig-paren">(</span><em class="sig-param">weight_file: str</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/claf/tokens/elmo.html#ElmoLstm.load_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.elmo.ElmoLstm.load_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the pre-trained weights from the file.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="claf.tokens.elmo.add_sentence_boundary_token_ids">
<code class="sig-prename descclassname">claf.tokens.elmo.</code><code class="sig-name descname">add_sentence_boundary_token_ids</code><span class="sig-paren">(</span><em class="sig-param">tensor: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">sentence_begin_token: Any</em>, <em class="sig-param">sentence_end_token: Any</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/claf/tokens/elmo.html#add_sentence_boundary_token_ids"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.elmo.add_sentence_boundary_token_ids" title="Permalink to this definition">¶</a></dt>
<dd><p>Add begin/end of sentence tokens to the batch of sentences.
Given a batch of sentences with size <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps)</span></code> or
<code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps,</span> <span class="pre">dim)</span></code> this returns a tensor of shape
<code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps</span> <span class="pre">+</span> <span class="pre">2)</span></code> or <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps</span> <span class="pre">+</span> <span class="pre">2,</span> <span class="pre">dim)</span></code> respectively.
Returns both the new tensor and updated mask.
Parameters
———-
tensor : <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></p>
<blockquote>
<div><p>A tensor of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps)</span></code> or <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps,</span> <span class="pre">dim)</span></code></p>
</div></blockquote>
<dl>
<dt>mask<span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></span></dt><dd><p>A tensor of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps)</span></code></p>
</dd>
<dt>sentence_begin_token: Any (anything that can be broadcast in torch for assignment)</dt><dd><p>For 2D input, a scalar with the &lt;S&gt; id. For 3D input, a tensor with length dim.</p>
</dd>
<dt>sentence_end_token: Any (anything that can be broadcast in torch for assignment)</dt><dd><p>For 2D input, a scalar with the &lt;/S&gt; id. For 3D input, a tensor with length dim.</p>
</dd>
</dl>
<dl>
<dt>tensor_with_boundary_tokens<span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></span></dt><dd><p>The tensor with the appended and prepended boundary tokens. If the input was 2D,
it has shape (batch_size, timesteps + 2) and if the input was 3D, it has shape
(batch_size, timesteps + 2, dim).</p>
</dd>
<dt>new_mask<span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></span></dt><dd><p>The new mask for the tensor, taking into account the appended tokens
marking the beginning and end of the sentence.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.elmo.remove_sentence_boundaries">
<code class="sig-prename descclassname">claf.tokens.elmo.</code><code class="sig-name descname">remove_sentence_boundaries</code><span class="sig-paren">(</span><em class="sig-param">tensor: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/claf/tokens/elmo.html#remove_sentence_boundaries"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.elmo.remove_sentence_boundaries" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove begin/end of sentence embeddings from the batch of sentences.
Given a batch of sentences with size <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps,</span> <span class="pre">dim)</span></code>
this returns a tensor of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps</span> <span class="pre">-</span> <span class="pre">2,</span> <span class="pre">dim)</span></code> after removing
the beginning and end sentence markers.  The sentences are assumed to be padded on the right,
with the beginning of each sentence assumed to occur at index 0 (i.e., <code class="docutils literal notranslate"><span class="pre">mask[:,</span> <span class="pre">0]</span></code> is assumed
to be 1).
Returns both the new tensor and updated mask.
This function is the inverse of <code class="docutils literal notranslate"><span class="pre">add_sentence_boundary_token_ids</span></code>.
Parameters
———-
tensor : <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></p>
<blockquote>
<div><p>A tensor of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps,</span> <span class="pre">dim)</span></code></p>
</div></blockquote>
<dl>
<dt>mask<span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></span></dt><dd><p>A tensor of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps)</span></code></p>
</dd>
</dl>
<dl>
<dt>tensor_without_boundary_tokens<span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></span></dt><dd><p>The tensor after removing the boundary tokens of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps</span> <span class="pre">-</span> <span class="pre">2,</span> <span class="pre">dim)</span></code></p>
</dd>
<dt>new_mask<span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></span></dt><dd><p>The new mask for the tensor of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">timesteps</span> <span class="pre">-</span> <span class="pre">2)</span></code>.</p>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-claf.tokens.hangul"></span><p>Hangulpy.py
Copyright (C) 2012 Ryan Rho, Hyunwoo Cho
Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the “Software”), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is furnished to do
so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</p>
<dl class="exception">
<dt id="claf.tokens.hangul.NotHangulException">
<em class="property">exception </em><code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">NotHangulException</code><a class="reference internal" href="_modules/claf/tokens/hangul.html#NotHangulException"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.NotHangulException" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#Exception" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></a></p>
</dd></dl>

<dl class="exception">
<dt id="claf.tokens.hangul.NotLetterException">
<em class="property">exception </em><code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">NotLetterException</code><a class="reference internal" href="_modules/claf/tokens/hangul.html#NotLetterException"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.NotLetterException" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#Exception" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></a></p>
</dd></dl>

<dl class="exception">
<dt id="claf.tokens.hangul.NotWordException">
<em class="property">exception </em><code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">NotWordException</code><a class="reference internal" href="_modules/claf/tokens/hangul.html#NotWordException"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.NotWordException" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#Exception" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></a></p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.add_ryul">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">add_ryul</code><span class="sig-paren">(</span><em class="sig-param">word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#add_ryul"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.add_ryul" title="Permalink to this definition">¶</a></dt>
<dd><p>add suffix either ‘률’ or ‘율’ at the end of this word</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.compose">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">compose</code><span class="sig-paren">(</span><em class="sig-param">chosung</em>, <em class="sig-param">joongsung</em>, <em class="sig-param">jongsung=''</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#compose"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.compose" title="Permalink to this definition">¶</a></dt>
<dd><p>This function returns a Hangul letter by composing the specified chosung, joongsung, and jongsung.
&#64;param chosung
&#64;param joongsung
&#64;param jongsung the terminal Hangul letter. This is optional if you do not need a jongsung.</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.decompose">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">decompose</code><span class="sig-paren">(</span><em class="sig-param">hangul_letter</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#decompose"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.decompose" title="Permalink to this definition">¶</a></dt>
<dd><p>This function returns letters by decomposing the specified Hangul letter.</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.has_approximant">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">has_approximant</code><span class="sig-paren">(</span><em class="sig-param">letter</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#has_approximant"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.has_approximant" title="Permalink to this definition">¶</a></dt>
<dd><p>Approximant makes complex vowels, such as ones starting with y or w.
In Korean there is a unique approximant euㅡ making uiㅢ, but ㅢ does not make many irregularities.</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.has_batchim">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">has_batchim</code><span class="sig-paren">(</span><em class="sig-param">letter</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#has_batchim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.has_batchim" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is the same as has_jongsung()</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.has_jongsung">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">has_jongsung</code><span class="sig-paren">(</span><em class="sig-param">letter</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#has_jongsung"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.has_jongsung" title="Permalink to this definition">¶</a></dt>
<dd><p>Check whether this letter contains Jongsung</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.ili">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">ili</code><span class="sig-paren">(</span><em class="sig-param">word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#ili"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.ili" title="Permalink to this definition">¶</a></dt>
<dd><p>convert {가} or {이} to their correct respective particles automagically.</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.is_all_hangul">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">is_all_hangul</code><span class="sig-paren">(</span><em class="sig-param">phrase</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#is_all_hangul"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.is_all_hangul" title="Permalink to this definition">¶</a></dt>
<dd><p>Check whether the phrase contains all Hangul letters
&#64;param phrase a target string
&#64;return True if the phrase only consists of Hangul. False otherwise.</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.is_hangul">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">is_hangul</code><span class="sig-paren">(</span><em class="sig-param">phrase</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#is_hangul"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.is_hangul" title="Permalink to this definition">¶</a></dt>
<dd><p>Check whether the phrase is Hangul.
This method ignores white spaces, punctuations, and numbers.
&#64;param phrase a target string
&#64;return True if the phrase is Hangul. False otherwise.</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.josa_eg">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">josa_eg</code><span class="sig-paren">(</span><em class="sig-param">word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#josa_eg"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.josa_eg" title="Permalink to this definition">¶</a></dt>
<dd><p>add josa either ‘이’ or ‘가’ at the end of this word</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.josa_el">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">josa_el</code><span class="sig-paren">(</span><em class="sig-param">word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#josa_el"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.josa_el" title="Permalink to this definition">¶</a></dt>
<dd><p>add josa either ‘을’ or ‘를’ at the end of this word</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.josa_en">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">josa_en</code><span class="sig-paren">(</span><em class="sig-param">word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#josa_en"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.josa_en" title="Permalink to this definition">¶</a></dt>
<dd><p>add josa either ‘은’ or ‘는’ at the end of this word</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.josa_gwa">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">josa_gwa</code><span class="sig-paren">(</span><em class="sig-param">word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#josa_gwa"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.josa_gwa" title="Permalink to this definition">¶</a></dt>
<dd><p>add josa either ‘과’ or ‘와’ at the end of this word</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.josa_ida">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">josa_ida</code><span class="sig-paren">(</span><em class="sig-param">word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#josa_ida"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.josa_ida" title="Permalink to this definition">¶</a></dt>
<dd><p>add josa either ‘이다’ or ‘다’ at the end of this word</p>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.hangul.josa_ro">
<code class="sig-prename descclassname">claf.tokens.hangul.</code><code class="sig-name descname">josa_ro</code><span class="sig-paren">(</span><em class="sig-param">word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/hangul.html#josa_ro"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.hangul.josa_ro" title="Permalink to this definition">¶</a></dt>
<dd><p>add josa either ‘으로’ or ‘로’ at the end of this word</p>
</dd></dl>

<span class="target" id="module-claf.tokens.linguistic"></span><dl class="class">
<dt id="claf.tokens.linguistic.NER">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.linguistic.</code><code class="sig-name descname">NER</code><a class="reference internal" href="_modules/claf/tokens/linguistic.html#NER"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.linguistic.NER" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Named Entity Recognition</p>
<p>Models trained on the OntoNotes 5 corpus support
the following entity types:
(<a class="reference external" href="https://spacy.io/api/annotation#section-dependency-parsing">https://spacy.io/api/annotation#section-dependency-parsing</a>)</p>
<dl class="attribute">
<dt id="claf.tokens.linguistic.NER.classes">
<code class="sig-name descname">classes</code><em class="property"> = ['NONE', 'PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'WORK_OF_ART', 'LAW', 'LANGUAGE', 'DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL']</em><a class="headerlink" href="#claf.tokens.linguistic.NER.classes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="claf.tokens.linguistic.POSTag">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.linguistic.</code><code class="sig-name descname">POSTag</code><a class="reference internal" href="_modules/claf/tokens/linguistic.html#POSTag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.linguistic.POSTag" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Universal POS tags expends by spacy
(<a class="reference external" href="https://spacy.io/api/annotation#section-pos-tagging">https://spacy.io/api/annotation#section-pos-tagging</a>)</p>
<dl class="attribute">
<dt id="claf.tokens.linguistic.POSTag.classes">
<code class="sig-name descname">classes</code><em class="property"> = ['ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'SPACE']</em><a class="headerlink" href="#claf.tokens.linguistic.POSTag.classes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<span class="target" id="module-claf.tokens.text_handler"></span><dl class="class">
<dt id="claf.tokens.text_handler.TextHandler">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.text_handler.</code><code class="sig-name descname">TextHandler</code><span class="sig-paren">(</span><em class="sig-param">token_makers</em>, <em class="sig-param">lazy_indexing=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/text_handler.html#TextHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.text_handler.TextHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Text Handler</p>
<ul class="simple">
<li><p>voacb and token_counter</p></li>
<li><p>raw_features -&gt; indexed_features</p></li>
<li><p>raw_features -&gt; tensor</p></li>
</ul>
<ul class="simple">
<li><dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>token_makers: Dictionary consisting of</dt><dd><ul>
<li><p>key: token_name</p></li>
<li><p>value: TokenMaker (claf.tokens.token_maker)</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Kwargs:</dt><dd><p>lazy_indexing: Apply <cite>Lazy Evaluation</cite> to text indexing</p>
</dd>
</dl>
</li>
</ul>
<dl class="method">
<dt id="claf.tokens.text_handler.TextHandler.build_vocabs">
<code class="sig-name descname">build_vocabs</code><span class="sig-paren">(</span><em class="sig-param">token_counters</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/text_handler.html#TextHandler.build_vocabs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.text_handler.TextHandler.build_vocabs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.text_handler.TextHandler.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">datas</em>, <em class="sig-param">text_columns</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/text_handler.html#TextHandler.index"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.text_handler.TextHandler.index" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.text_handler.TextHandler.is_all_vocab_use_pretrained">
<code class="sig-name descname">is_all_vocab_use_pretrained</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/text_handler.html#TextHandler.is_all_vocab_use_pretrained"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.text_handler.TextHandler.is_all_vocab_use_pretrained" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.text_handler.TextHandler.make_token_counters">
<code class="sig-name descname">make_token_counters</code><span class="sig-paren">(</span><em class="sig-param">texts</em>, <em class="sig-param">config=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/text_handler.html#TextHandler.make_token_counters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.text_handler.TextHandler.make_token_counters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.text_handler.TextHandler.raw_to_tensor_fn">
<code class="sig-name descname">raw_to_tensor_fn</code><span class="sig-paren">(</span><em class="sig-param">data_reader</em>, <em class="sig-param">cuda_device=None</em>, <em class="sig-param">helper={}</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/text_handler.html#TextHandler.raw_to_tensor_fn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.text_handler.TextHandler.raw_to_tensor_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<span class="target" id="module-claf.tokens.token_maker"></span><dl class="class">
<dt id="claf.tokens.token_maker.TokenMaker">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.token_maker.</code><code class="sig-name descname">TokenMaker</code><span class="sig-paren">(</span><em class="sig-param">token_type</em>, <em class="sig-param">tokenizer=None</em>, <em class="sig-param">indexer=None</em>, <em class="sig-param">embedding_fn=None</em>, <em class="sig-param">vocab_config=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/token_maker.html#TokenMaker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Token Maker (Data Transfer Object)</p>
<p>Token Maker consists of Tokenizer, Indexer, Embedding and Vocab</p>
<ul class="simple">
<li><dl class="simple">
<dt>Kwargs:</dt><dd><p>tokenizer: Tokenizer (claf.tokens.tokenizer.base)
indexer: TokenIndexer (claf.tokens.indexer.base)
embedding_fn: wrapper function of TokenEmbedding (claf.tokens.embedding.base)
vocab_config: config dict of Vocab (claf.tokens.vocaburary)</p>
</dd>
</dl>
</li>
</ul>
<dl class="attribute">
<dt id="claf.tokens.token_maker.TokenMaker.BERT_TYPE">
<code class="sig-name descname">BERT_TYPE</code><em class="property"> = 'bert'</em><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.BERT_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.token_maker.TokenMaker.CHAR_TYPE">
<code class="sig-name descname">CHAR_TYPE</code><em class="property"> = 'char'</em><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.CHAR_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.token_maker.TokenMaker.COVE_TYPE">
<code class="sig-name descname">COVE_TYPE</code><em class="property"> = 'cove'</em><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.COVE_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.token_maker.TokenMaker.ELMO_TYPE">
<code class="sig-name descname">ELMO_TYPE</code><em class="property"> = 'elmo'</em><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.ELMO_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.token_maker.TokenMaker.EXACT_MATCH_TYPE">
<code class="sig-name descname">EXACT_MATCH_TYPE</code><em class="property"> = 'exact_match'</em><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.EXACT_MATCH_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.token_maker.TokenMaker.FEATURE_TYPE">
<code class="sig-name descname">FEATURE_TYPE</code><em class="property"> = 'feature'</em><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.FEATURE_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.token_maker.TokenMaker.FREQUENT_WORD_TYPE">
<code class="sig-name descname">FREQUENT_WORD_TYPE</code><em class="property"> = 'frequent_word'</em><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.FREQUENT_WORD_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.token_maker.TokenMaker.LINGUISTIC_TYPE">
<code class="sig-name descname">LINGUISTIC_TYPE</code><em class="property"> = 'linguistic'</em><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.LINGUISTIC_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.token_maker.TokenMaker.WORD_TYPE">
<code class="sig-name descname">WORD_TYPE</code><em class="property"> = 'word'</em><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.WORD_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.token_maker.TokenMaker.embedding_fn">
<em class="property">property </em><code class="sig-name descname">embedding_fn</code><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.embedding_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.token_maker.TokenMaker.indexer">
<em class="property">property </em><code class="sig-name descname">indexer</code><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.indexer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.token_maker.TokenMaker.set_vocab">
<code class="sig-name descname">set_vocab</code><span class="sig-paren">(</span><em class="sig-param">vocab</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/token_maker.html#TokenMaker.set_vocab"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.set_vocab" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.token_maker.TokenMaker.tokenizer">
<em class="property">property </em><code class="sig-name descname">tokenizer</code><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.tokenizer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.token_maker.TokenMaker.vocab">
<em class="property">property </em><code class="sig-name descname">vocab</code><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.vocab" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.token_maker.TokenMaker.vocab_config">
<em class="property">property </em><code class="sig-name descname">vocab_config</code><a class="headerlink" href="#claf.tokens.token_maker.TokenMaker.vocab_config" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<span class="target" id="module-claf.tokens.vocabulary"></span><dl class="class">
<dt id="claf.tokens.vocabulary.Vocab">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.vocabulary.</code><code class="sig-name descname">Vocab</code><span class="sig-paren">(</span><em class="sig-param">token_name</em>, <em class="sig-param">pad_token=None</em>, <em class="sig-param">oov_token=None</em>, <em class="sig-param">start_token=None</em>, <em class="sig-param">end_token=None</em>, <em class="sig-param">cls_token=None</em>, <em class="sig-param">sep_token=None</em>, <em class="sig-param">min_count=None</em>, <em class="sig-param">max_vocab_size=None</em>, <em class="sig-param">frequent_count=None</em>, <em class="sig-param">pretrained_path=None</em>, <em class="sig-param">pretrained_token=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<blockquote>
<div><p>Vocaburary Class</p>
<p>Vocab consists of token_to_index and index_to_token.</p>
<ul>
<li><dl class="simple">
<dt>Args:</dt><dd><p>token_name: Token name (Token and Vocab is one-to-one relationship)</p>
</dd>
</dl>
</li>
<li><dl>
<dt>Kwargs:</dt><dd><p>pad_token: padding token value (eg. &lt;pad&gt;)
oov_token: out-of-vocaburary token value (eg. &lt;unk&gt;)
start_token: start token value (eg. &lt;s&gt;, &lt;bos&gt;)
end_token: end token value (eg. &lt;/s&gt;, &lt;eos&gt;)
cls_token: CLS token value for BERT (eg. [CLS])
sep_token: SEP token value for BERT (eg. [SEP])
min_count: token’s minimal frequent count.</p>
<blockquote>
<div><p>when you define min_count, tokens remain that bigger than min_count.</p>
</div></blockquote>
<dl class="simple">
<dt>max_vocab_size: vocaburary’s maximun size.</dt><dd><p>when you define max_vocab_size, tokens are selected according to frequent count.</p>
</dd>
<dt>frequent_count: get frequent_count threshold_index.</dt><dd><p>(eg. frequent_count = 1000, threshold_index is the tokens that frequent_count is 999 index number.)</p>
</dd>
<dt>pretrained_path: pretrained vocab file path</dt><dd><p>(format: A</p>
</dd>
</dl>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p>B
C
D
…)</p>
<dl class="attribute">
<dt id="claf.tokens.vocabulary.Vocab.DEFAULT_OOV_INDEX">
<code class="sig-name descname">DEFAULT_OOV_INDEX</code><em class="property"> = 1</em><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.DEFAULT_OOV_INDEX" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.vocabulary.Vocab.DEFAULT_OOV_TOKEN">
<code class="sig-name descname">DEFAULT_OOV_TOKEN</code><em class="property"> = '[UNK]'</em><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.DEFAULT_OOV_TOKEN" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.vocabulary.Vocab.DEFAULT_PAD_INDEX">
<code class="sig-name descname">DEFAULT_PAD_INDEX</code><em class="property"> = 0</em><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.DEFAULT_PAD_INDEX" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.vocabulary.Vocab.DEFAULT_PAD_TOKEN">
<code class="sig-name descname">DEFAULT_PAD_TOKEN</code><em class="property"> = '[PAD]'</em><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.DEFAULT_PAD_TOKEN" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.vocabulary.Vocab.PRETRAINED_ALL">
<code class="sig-name descname">PRETRAINED_ALL</code><em class="property"> = 'all'</em><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.PRETRAINED_ALL" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="claf.tokens.vocabulary.Vocab.PRETRAINED_INTERSECT">
<code class="sig-name descname">PRETRAINED_INTERSECT</code><em class="property"> = 'intersect'</em><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.PRETRAINED_INTERSECT" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.add">
<code class="sig-name descname">add</code><span class="sig-paren">(</span><em class="sig-param">token</em>, <em class="sig-param">predefine_vocab=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.add" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">token_counter</em>, <em class="sig-param">predefine_vocab=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.build" title="Permalink to this definition">¶</a></dt>
<dd><p>build token with token_counter</p>
<ul class="simple">
<li><dl class="simple">
<dt>Args:</dt><dd><p>token_counter: (collections.Counter) token’s frequent_count Counter.</p>
</dd>
</dl>
</li>
</ul>
</dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.build_with_pretrained_file">
<code class="sig-name descname">build_with_pretrained_file</code><span class="sig-paren">(</span><em class="sig-param">token_counter</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.build_with_pretrained_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.build_with_pretrained_file" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.dump">
<code class="sig-name descname">dump</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.dump"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.dump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.from_texts">
<code class="sig-name descname">from_texts</code><span class="sig-paren">(</span><em class="sig-param">texts</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.from_texts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.from_texts" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.get_all_tokens">
<code class="sig-name descname">get_all_tokens</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.get_all_tokens"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.get_all_tokens" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.get_index">
<code class="sig-name descname">get_index</code><span class="sig-paren">(</span><em class="sig-param">token</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.get_index"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.get_index" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.get_token">
<code class="sig-name descname">get_token</code><span class="sig-paren">(</span><em class="sig-param">index</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.get_token"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.get_token" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.init">
<code class="sig-name descname">init</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.init"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.load" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="claf.tokens.vocabulary.Vocab.to_text">
<code class="sig-name descname">to_text</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#Vocab.to_text"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.Vocab.to_text" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="claf.tokens.vocabulary.VocabDict">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.vocabulary.</code><code class="sig-name descname">VocabDict</code><span class="sig-paren">(</span><em class="sig-param">oov_value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens/vocabulary.html#VocabDict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.vocabulary.VocabDict" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/collections.html#collections.defaultdict" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">collections.defaultdict</span></code></a></p>
<p>Vocab DefaultDict Class</p>
<ul class="simple">
<li><dl class="simple">
<dt>Kwargs:</dt><dd><p>oov_value: out-of-vocaburary token value (eg. &lt;unk&gt;)</p>
</dd>
</dl>
</li>
</ul>
</dd></dl>

</div>
<div class="section" id="module-claf.tokens">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-claf.tokens" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="claf.tokens.BertTokenMaker">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.</code><code class="sig-name descname">BertTokenMaker</code><span class="sig-paren">(</span><em class="sig-param">tokenizers</em>, <em class="sig-param">indexer_config</em>, <em class="sig-param">embedding_config</em>, <em class="sig-param">vocab_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens.html#BertTokenMaker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.BertTokenMaker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#claf.tokens.token_maker.TokenMaker" title="claf.tokens.token_maker.TokenMaker"><code class="xref py py-class docutils literal notranslate"><span class="pre">claf.tokens.token_maker.TokenMaker</span></code></a></p>
<p>BERT Token
Pre-training of Deep Bidirectional Transformers for Language Understanding</p>
<dl class="simple">
<dt>example.</dt><dd><p>hello -&gt; [‘[CLS]’, ‘he’, ‘##llo’, [SEP]] -&gt; [1, 4, 7, 2] -&gt; BERT -&gt; tensor</p>
</dd>
<dt>consisting of</dt><dd><ul class="simple">
<li><p>tokenizer: WordTokenizer</p></li>
<li><p>indexer: WordIndexer</p></li>
<li><p>embedding: ELMoEmbedding (Language Modeling BiLSTM)</p></li>
<li><p>vocab: Vocab</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="claf.tokens.CharTokenMaker">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.</code><code class="sig-name descname">CharTokenMaker</code><span class="sig-paren">(</span><em class="sig-param">tokenizers</em>, <em class="sig-param">indexer_config</em>, <em class="sig-param">embedding_config</em>, <em class="sig-param">vocab_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens.html#CharTokenMaker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.CharTokenMaker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#claf.tokens.token_maker.TokenMaker" title="claf.tokens.token_maker.TokenMaker"><code class="xref py py-class docutils literal notranslate"><span class="pre">claf.tokens.token_maker.TokenMaker</span></code></a></p>
<p>Character Token</p>
<p>Character-level Convolutional Networks for Text Classification
(<a class="reference external" href="https://arxiv.org/abs/1509.01626">https://arxiv.org/abs/1509.01626</a>)</p>
<dl class="simple">
<dt>example.</dt><dd><p>hello -&gt; [‘h’, ‘e’, ‘l’, ‘l’, ‘o’] -&gt; [2, 3, 4, 4, 5] -&gt; CharCNN -&gt; tensor</p>
</dd>
<dt>consisting of</dt><dd><ul class="simple">
<li><p>tokenizer: CharTokenizer</p></li>
<li><p>indexer: CharIndexer</p></li>
<li><p>embedding: CharEmbedding (CharCNN)</p></li>
<li><p>vocab: Vocab</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="claf.tokens.CoveTokenMaker">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.</code><code class="sig-name descname">CoveTokenMaker</code><span class="sig-paren">(</span><em class="sig-param">tokenizers</em>, <em class="sig-param">indexer_config</em>, <em class="sig-param">embedding_config</em>, <em class="sig-param">vocab_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens.html#CoveTokenMaker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.CoveTokenMaker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#claf.tokens.token_maker.TokenMaker" title="claf.tokens.token_maker.TokenMaker"><code class="xref py py-class docutils literal notranslate"><span class="pre">claf.tokens.token_maker.TokenMaker</span></code></a></p>
<p>CoVe Token</p>
<p>Learned in Translation: Contextualized Word Vectors (McCann et. al. 2017)
(<a class="reference external" href="https://github.com/salesforce/cove">https://github.com/salesforce/cove</a>)</p>
<dl class="simple">
<dt>example.</dt><dd><p>hello -&gt; [‘hello’] -&gt; [2] -&gt; CoVe -&gt; tensor</p>
</dd>
<dt>consisting of</dt><dd><ul class="simple">
<li><p>tokenizer: WordTokenizer</p></li>
<li><p>indexer: WordIndexer</p></li>
<li><p>embedding: CoveEmbedding (Machine Translation LSTM)</p></li>
<li><p>vocab: Vocab</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="claf.tokens.ElmoTokenMaker">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.</code><code class="sig-name descname">ElmoTokenMaker</code><span class="sig-paren">(</span><em class="sig-param">tokenizers</em>, <em class="sig-param">indexer_config</em>, <em class="sig-param">embedding_config</em>, <em class="sig-param">vocab_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens.html#ElmoTokenMaker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.ElmoTokenMaker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#claf.tokens.token_maker.TokenMaker" title="claf.tokens.token_maker.TokenMaker"><code class="xref py py-class docutils literal notranslate"><span class="pre">claf.tokens.token_maker.TokenMaker</span></code></a></p>
<p>ELMo Token
Embedding from Language Modeling</p>
<p>Deep contextualized word representations
(<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/modules/elmo.py">https://github.com/allenai/allennlp/blob/master/allennlp/modules/elmo.py</a>)</p>
<dl class="simple">
<dt>example.</dt><dd><p>hello -&gt; [‘h’, ‘e’, ‘l’, ‘l’, ‘o’] -&gt; [2, 3, 4, 4, 5] -&gt; ELMo -&gt; tensor</p>
</dd>
<dt>consisting of</dt><dd><ul class="simple">
<li><p>tokenizer: WordTokenizer</p></li>
<li><p>indexer: WordIndexer</p></li>
<li><p>embedding: ELMoEmbedding (Language Modeling BiLSTM)</p></li>
<li><p>vocab: Vocab</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="claf.tokens.ExactMatchTokenMaker">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.</code><code class="sig-name descname">ExactMatchTokenMaker</code><span class="sig-paren">(</span><em class="sig-param">tokenizers</em>, <em class="sig-param">indexer_config</em>, <em class="sig-param">embedding_config</em>, <em class="sig-param">vocab_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens.html#ExactMatchTokenMaker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.ExactMatchTokenMaker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#claf.tokens.token_maker.TokenMaker" title="claf.tokens.token_maker.TokenMaker"><code class="xref py py-class docutils literal notranslate"><span class="pre">claf.tokens.token_maker.TokenMaker</span></code></a></p>
<p>Exact Match Token (Sparse Feature)</p>
<p>Three simple binary features, indicating whether p_i can be exactly matched
to one question word in q, either in its original, lowercase or lemma form.</p>
<dl class="simple">
<dt>example.</dt><dd><p>c: i do, q: i -&gt; [‘i’, ‘do’] -&gt; [1, 0] -&gt; tensor</p>
</dd>
<dt>consisting of</dt><dd><ul class="simple">
<li><p>tokenizer: WordTokenizer</p></li>
<li><p>indexer: WordIndexer</p></li>
<li><p>embedding: SparseFeature</p></li>
<li><p>vocab: Vocab</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="claf.tokens.FeatureTokenMaker">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.</code><code class="sig-name descname">FeatureTokenMaker</code><span class="sig-paren">(</span><em class="sig-param">tokenizers</em>, <em class="sig-param">indexer_config</em>, <em class="sig-param">embedding_config</em>, <em class="sig-param">vocab_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens.html#FeatureTokenMaker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.FeatureTokenMaker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#claf.tokens.token_maker.TokenMaker" title="claf.tokens.token_maker.TokenMaker"><code class="xref py py-class docutils literal notranslate"><span class="pre">claf.tokens.token_maker.TokenMaker</span></code></a></p>
<p>Feature Token</p>
<p>Do not use Embedding function.
Just pass indexed_feature</p>
<dl class="simple">
<dt>example.</dt><dd><p>hello -&gt; [‘hello’, ‘world’] -&gt; [3, 5] -&gt; tensor</p>
</dd>
<dt>consisting of</dt><dd><ul class="simple">
<li><p>tokenizer: Tokenizer (need to define unit)</p></li>
<li><p>indexer: WordIndexer</p></li>
<li><p>embedding: None</p></li>
<li><p>vocab: Vocab</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="claf.tokens.FrequentWordTokenMaker">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.</code><code class="sig-name descname">FrequentWordTokenMaker</code><span class="sig-paren">(</span><em class="sig-param">tokenizers</em>, <em class="sig-param">indexer_config</em>, <em class="sig-param">embedding_config</em>, <em class="sig-param">vocab_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens.html#FrequentWordTokenMaker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.FrequentWordTokenMaker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#claf.tokens.token_maker.TokenMaker" title="claf.tokens.token_maker.TokenMaker"><code class="xref py py-class docutils literal notranslate"><span class="pre">claf.tokens.token_maker.TokenMaker</span></code></a></p>
<p>Frequent-Tuning Word Token</p>
<p>word token + pre-trained word embeddings fixed and only fine-tune the N most frequent</p>
<dl class="simple">
<dt>example.</dt><dd><p>i do -&gt; [‘i’, ‘do’] -&gt; [1, 2] -&gt; Embedding Matrix -&gt; tensor
finetuning only ‘do’</p>
</dd>
<dt>consisting of</dt><dd><ul class="simple">
<li><p>tokenizer: WordTokenizer</p></li>
<li><p>indexer: WordIndexer</p></li>
<li><p>embedding: FrequentTuningWordEmbedding</p></li>
<li><p>vocab: Vocab</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="claf.tokens.LinguisticTokenMaker">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.</code><code class="sig-name descname">LinguisticTokenMaker</code><span class="sig-paren">(</span><em class="sig-param">tokenizers</em>, <em class="sig-param">indexer_config</em>, <em class="sig-param">embedding_config</em>, <em class="sig-param">vocab_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens.html#LinguisticTokenMaker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.LinguisticTokenMaker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#claf.tokens.token_maker.TokenMaker" title="claf.tokens.token_maker.TokenMaker"><code class="xref py py-class docutils literal notranslate"><span class="pre">claf.tokens.token_maker.TokenMaker</span></code></a></p>
<p>Exact Match Token (Sparse Feature)</p>
<p>Three simple binary features, indicating whether p_i can be exactly matched
to one question word in q, either in its original, lowercase or lemma form.</p>
<dl class="simple">
<dt>example.</dt><dd><p>c: i do, q: i -&gt; [‘i’, ‘do’] -&gt; [1, 0] -&gt; tensor</p>
</dd>
<dt>consisting of</dt><dd><ul class="simple">
<li><p>tokenizer: WordTokenizer</p></li>
<li><p>indexer: WordIndexer</p></li>
<li><p>embedding: SparseFeature</p></li>
<li><p>vocab: Vocab</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="claf.tokens.WordTokenMaker">
<em class="property">class </em><code class="sig-prename descclassname">claf.tokens.</code><code class="sig-name descname">WordTokenMaker</code><span class="sig-paren">(</span><em class="sig-param">tokenizers</em>, <em class="sig-param">indexer_config</em>, <em class="sig-param">embedding_config</em>, <em class="sig-param">vocab_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens.html#WordTokenMaker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.WordTokenMaker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#claf.tokens.token_maker.TokenMaker" title="claf.tokens.token_maker.TokenMaker"><code class="xref py py-class docutils literal notranslate"><span class="pre">claf.tokens.token_maker.TokenMaker</span></code></a></p>
<p>Word Token (default)</p>
<blockquote>
<div><p>i do -&gt; [‘i’, ‘do’] -&gt; [1, 2] -&gt; Embedding Matrix -&gt; tensor</p>
</div></blockquote>
<dl class="simple">
<dt>consisting of</dt><dd><ul class="simple">
<li><p>tokenizer: WordTokenizer</p></li>
<li><p>indexer: WordIndexer</p></li>
<li><p>embedding: WordEmbedding</p></li>
<li><p>vocab: Vocab</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="claf.tokens.basic_embedding_fn">
<code class="sig-prename descclassname">claf.tokens.</code><code class="sig-name descname">basic_embedding_fn</code><span class="sig-paren">(</span><em class="sig-param">embedding_config</em>, <em class="sig-param">module</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/claf/tokens.html#basic_embedding_fn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#claf.tokens.basic_embedding_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="claf.tokens.embedding.html" class="btn btn-neutral float-right" title="claf.tokens.embedding package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="claf.modules.layer.html" class="btn btn-neutral" title="claf.modules.layer package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Dongjun Lee

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>